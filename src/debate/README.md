In round 1, 7b_correct_initial.py and 7b_incorrect_initial.py are employed to generate initial explanations. The sole distinction between these two files lies in the usage of the words "correct" and "incorrect" in the prompt.
The demo_correct_initial.json and demo_incorrect_initial.json are ICL demonstrations used in round 1.

In subsequent debates, 7b_correct.py and 7b_incorrect.py are utilized. Similarly, these two files only differ in the presence of "correct" and "incorrect" in the prompt.
The demo_correct.json and demo_incorrect.json are ICL demonstrations used in subsequent debates.

The merge.py script is used to combine the explanations generated by the two 7b models into a single file for easier subsequent file reading.

The 1.8b-chat model utilizes 1.8b_chat_debate.py to annotate the data based on the debate outcomes.

The training code is the same as interaction-enhanced-SO.

7b debate -> merge -> 1.8b annotation -> train 7b